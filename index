video_progress = {}

# Hàm kiểm tra và lấy đường dẫn ffmpeg
def get_ffmpeg_bin(ffmpeg_path):
    if ffmpeg_path and os.path.exists(os.path.join(ffmpeg_path, "ffmpeg.exe")):
        return ffmpeg_path
    default_path = os.path.join(os.getcwd(), "ffmpeg/bin")
    if os.path.exists(os.path.join(default_path, "ffmpeg.exe")):
        return default_path
    else:
        messagebox.showerror("Error", "Không tìm thấy FFmpeg. Vui lòng kiểm tra lại.")
        return None

# Hàm mã hóa tên video ngắn gọn
def hash_video_name(input_str):
    ascii_str = input_str.encode('ascii', 'ignore').decode('ascii')
    
    # Loại bỏ các ký tự không phải chữ và số
    cleaned_str = ''.join(char for char in ascii_str if char.isalnum())
    
    return cleaned_str

# Hàm tách khung hình và âm thanh
def process_video(video_path, interval, ffmpeg_bin):
    try:
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        video_key = hash_video_name(video_name)
        frame_output_dir = f"frames/{video_name}"
        audio_output = f"{frame_output_dir}/audio.wav"
        result_video = f"result/{video_name}.mp4"
        
        os.makedirs(frame_output_dir, exist_ok=True)
        os.makedirs("result", exist_ok=True)

        # Tách khung hình
        output_path = os.path.join(frame_output_dir, 'frame_%04d.png')
        ffmpeg.input(video_path).output(output_path, vf=f'fps=1/{interval}').run(cmd=os.path.join(ffmpeg_bin, 'ffmpeg'), quiet = True)

        # Tách âm thanh
        ffmpeg.input(video_path).output(audio_output, vn=None).run(cmd=os.path.join(ffmpeg_bin, 'ffmpeg'), quiet = True)

        # Tạo video mới từ các khung hình và âm thanh
        create_video_with_transitions(frame_output_dir, interval, audio_output, result_video, ffmpeg_bin, video_key)

    except Exception as e:
        messagebox.showerror("Error", f"Lỗi khi xử lý video: {e}")

def smooth_ease_in(x, p=1.5):
    # Easing bắt đầu nhanh hơn và chậm dần
    return 1 - (1 - x) ** p

def create_zoomin_video(image_path, output_path, duration=5, fps=120):
    img = cv2.imread(image_path)
    height, width = img.shape[:2]
    
    # Tạo nền mờ
    background = cv2.GaussianBlur(img, (31, 31), 0)
    
    scale = 0.3  # Tỷ lệ thu nhỏ ban đầu
    small_width = int(width * scale)
    small_height = int(height * scale)
    small_img = cv2.resize(img, (small_width, small_height))
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    total_frames = duration * fps
    for frame_num in range(total_frames):
        frame = background.copy()
        
        # Tính tiến trình và áp dụng easing
        progress = frame_num / total_frames
        eased_progress = smooth_ease_in(progress)
        
        # Tính tỷ lệ zoom
        zoom = 1.0 + (2.33 * eased_progress)
        
        current_width = int(small_width * zoom)
        current_height = int(small_height * zoom)
        
        # Giới hạn kích thước để không vượt quá khung hình
        current_width = min(current_width, width)
        current_height = min(current_height, height)
        
        # Zoom ảnh với interpolation cao cấp
        zoomed_img = cv2.resize(small_img, (current_width, current_height), 
                                interpolation=cv2.INTER_LANCZOS4)
        
        # Tính toán vị trí crop để căn giữa
        x = (width - current_width) // 2
        y = (height - current_height) // 2
        
        # Đảm bảo không bị rung bằng cách tính tọa độ mượt mà
        x = max(0, x)
        y = max(0, y)
        
        # Căn chỉnh và ghép ảnh
        frame[y:y+current_height, x:x+current_width] = zoomed_img
        out.write(frame)
    
    out.release()

def smooth_ease_out(x, p=0.35):
    # Easing chậm ban đầu và nhanh dần
    return x ** p

def create_zoomout_video(image_path, output_path, duration=5, fps=120):
    img = cv2.imread(image_path)
    height, width = img.shape[:2]
    
    # Tạo nền mờ
    background = cv2.GaussianBlur(img, (31, 31), 0)
    
    # Tỷ lệ thu nhỏ tối thiểu và phóng to ban đầu
    start_scale = 1.2  # 120%
    end_scale = 0.3    # 30%
    small_width = int(width * end_scale)
    small_height = int(height * end_scale)
    small_img = cv2.resize(img, (small_width, small_height))
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    total_frames = duration * fps
    for frame_num in range(total_frames):
        frame = background.copy()
        
        # Tính tiến trình và áp dụng easing
        progress = frame_num / total_frames
        eased_progress = smooth_ease_out(progress)
        
        # Tính tỷ lệ zoom giảm dần từ 120% về 30%
        zoom = start_scale - (start_scale - end_scale) * eased_progress
        
        current_width = int(width * zoom)
        current_height = int(height * zoom)
        
        # Giới hạn kích thước để không vượt quá khung hình
        current_width = min(current_width, width)
        current_height = min(current_height, height)
        
        # Zoom ảnh với interpolation cao cấp
        zoomed_img = cv2.resize(img, (current_width, current_height), 
                                interpolation=cv2.INTER_LANCZOS4)
        
        # Tính toán vị trí crop để căn giữa
        x = (width - current_width) // 2
        y = (height - current_height) // 2
        
        # Đảm bảo không bị rung bằng cách tính tọa độ mượt mà
        x = max(0, x)
        y = max(0, y)
        
        # Căn chỉnh và ghép ảnh
        frame[y:y+current_height, x:x+current_width] = zoomed_img
        out.write(frame)
    
    out.release()


# Hàm tạo video mới từ các khung hình và giữ âm thanh gốc với hiệu ứng chuyển cảnh
def create_video_with_transitions(frame_dir, interval, audio_path, output_video, ffmpeg_bin, video_key):
    try:
        animations = ["movedown", "moveup", "zoomin", "zoomout"]
        
        images = sorted([os.path.join(frame_dir, f) for f in os.listdir(frame_dir) if f.endswith(".png")])
        
        processed_images = []
        for img_name in images:
            img_path = img_name
            img = Image.open(img_path)
            suffix = ""
            if mirror_var.get() and bw_var.get():
                img = ImageOps.mirror(img)
                img = img.convert('L')
                suffix = "_mirror_bw"
            elif mirror_var.get():
                img = ImageOps.mirror(img)
                suffix = "_mirror"
            elif bw_var.get():
                img = img.convert('L')
                suffix = "_bw"
                
            if suffix:
                new_name = os.path.splitext(img_name)[0] + ".png"
                save_path = new_name
                img.save(save_path)
                print(f"Saved image: {save_path}")
                processed_images.append(save_path)
            else:
                processed_images.append(img_path)
        images = processed_images
        if len(images) < 1:
            raise Exception("Cần ít nhất 1 ảnh để tạo video.")
        def process_video(images, lock, current_index, temp_videos, frame_dir, interval, ffmpeg_bin, animations):
            while True:
                with lock:
                    if current_index[0] >= len(images):
                        break
                    i = current_index[0]
                    current_index[0] += 1
                    
                image = images[i]
                temp_video = os.path.join(frame_dir, f"temp_{i}.mp4")
                animation = animations[int(time.time()) % len(animations)]
                
                filter_complex = [
                    "[0:v]format=yuv420p,split=2[bg][fg]",
                    "[bg]scale=1920:1080,boxblur=20:20[blurred]"
                ]
                if animation == "movedown":
                    filter_complex.append("[fg]scale=1280:720[fg1]")
                    filter_complex.append("[blurred][fg1]overlay=(W-w)/2:'if(between(t,0,5),0-h+t*180,180)'[v]")
                elif animation == "moveup":
                    filter_complex.append("[fg]scale=1280:720[fg1]")
                    filter_complex.append("[blurred][fg1]overlay=(W-w)/2:'if(between(t,0,5),1080-t*180,180)'[v]")
                elif animation == "zoomin":
                    create_zoomin_video(image, temp_video, interval)
                elif animation == "zoomout":
                    create_zoomout_video(image, temp_video, interval)


                command = [
                    os.path.join(ffmpeg_bin, 'ffmpeg'),
                    '-y',
                    '-loop', '1',
                    '-t', str(interval),
                    '-i', image,
                    '-filter_complex', ';'.join(filter_complex),
                    '-map', '[v]',
                    '-c:v', 'libx264',
                    temp_video
                ]
                
                process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                output, error = process.communicate()
                open("log.txt", "a").write(f"Output: {output}\nError: {error}\n")
                print(f"Processed image: {image}")
                
                with lock:
                    temp_videos.append(temp_video)

        # Main processing
        lock = threading.Lock()
        current_index = [0]  # Using list to make it mutable
        threads = []
        temp_videos = []

        # Start workers
        num_threads = min(50, len(images))
        for _ in range(num_threads):
            t = threading.Thread(target=process_video, 
                                args=(images, lock, current_index, temp_videos,
                                    frame_dir, interval, ffmpeg_bin, animations))
            threads.append(t)
            t.start()

        # Wait for completion 
        for t in threads:
            t.join()

        # Kiểm tra file tạm thời và tạo concat_list.txt
        concat_list_file = os.path.join(frame_dir, "concat_list.txt")
        with open(concat_list_file, "w") as f:
            for temp_video in temp_videos:
                f.write(f"file '{os.path.abspath(temp_video)}'\n")

        # Lệnh FFmpeg để ghép nối video cuối cùng
        final_command = [
            os.path.join(ffmpeg_bin, 'ffmpeg'),
            '-y',
            '-f', 'concat', '-safe', '0', '-i', concat_list_file,
            '-i', audio_path,
            '-c:v', 'libx264', '-c:a', 'aac', '-b:a', '192k',
            output_video
        ]

        subprocess.Popen(final_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()
    except Exception as e:
        tb = e.__traceback__
        error_message = f"Exception: {e} | "
        while tb is not None:
            filename = tb.tb_frame.f_code.co_filename
            lineno = tb.tb_lineno
            function_name = tb.tb_frame.f_code.co_name
            error_message += f"File: {filename}, Line: {lineno}, in {function_name}\n"
            tb = tb.tb_next
        open("log.txt", "a").write(f"{error_message}\n")
        messagebox.showerror("Error", f"Lỗi khi tạo video với hiệu ứng: {e}")

# Cập nhật tiến trình của từng video và tính tiến trình tổng
def update_individual_progress(video_key, progress):
    video_progress[video_key] = progress
    total_progress = sum(video_progress.values()) / len(video_progress)


# Giao diện xử lý
def process_videos_in_threads():
    def run():
        video_dir = file_path_entry.get()
        print(ffmpeg_path_entry.get())
        ffmpeg_bin = get_ffmpeg_bin(ffmpeg_path_entry.get())
        interval = float(interval_entry.get())

        if not os.path.exists(video_dir):
            messagebox.showerror("Error", "Thư mục video không tồn tại!")
            return
        video_files = [os.path.join(video_dir, f) for f in os.listdir(video_dir) if f.endswith(".mp4")]

        def process_task(lock):
            with lock:
                video = video_files.pop(0)
                video_name = os.path.splitext(os.path.basename(video))[0]
                video_key = hash_video_name(video_name)
                video_progress[video_key] = 0 
            process_video(video, interval, ffmpeg_bin)

        threads = []
        so_luong = int(luong.get())
        for i in range(so_luong):
                t = threading.Thread(target=process_task, args=(threading.Lock(),))
                threads.append(t)

        for t in threads:
            t.start()
        for t in threads:
            t.join()

        messagebox.showinfo("Success", "Đã hoàn thành xử lý tất cả video.")
    threading.Thread(target=run).start()


# Giao diện CustomTkinter
app = ctk.CTk()
app.title("Quản lý Video FFmpeg đa luồng")
app.geometry("500x650")

ctk.CTkLabel(app, text="Thư mục chứa video MP4").pack(pady=5)
file_path_entry = ctk.CTkEntry(app, placeholder_text="Nhập đường dẫn đến thư mục video", width=400)
file_path_entry.pack(pady=5)
ctk.CTkButton(app, text="Chọn Thư Mục", command=lambda: file_path_entry.insert(0, filedialog.askdirectory())).pack(pady=5)

ctk.CTkLabel(app, text="Đường dẫn FFmpeg (để trống nếu mặc định)").pack(pady=5)
ffmpeg_path_entry = ctk.CTkEntry(app, placeholder_text="Nhập đường dẫn thư mục ffmpeg/bin", width=400)
ffmpeg_path_entry.pack(pady=5)
ctk.CTkButton(app, text="Chọn Đường Dẫn", command=lambda: ffmpeg_path_entry.insert(0, filedialog.askdirectory())).pack(pady=5)

ctk.CTkLabel(app, text="Khoảng thời gian giữa các ảnh (giây)").pack(pady=5)
interval_entry = ctk.CTkEntry(app, placeholder_text="Nhập số giây", width=200)
interval_entry.pack(pady=5)


ctk.CTkLabel(app, text="Số luồng").pack(pady=5)
luong = ctk.CTkEntry(app, placeholder_text="Nhập số luồng", width=200)
luong.pack(pady=5)

# Add after other imports
mirror_var = ctk.BooleanVar()
bw_var = ctk.BooleanVar()

# Add before app.mainloop()
ctk.CTkLabel(app, text="Hiệu ứng ảnh").pack(pady=5)
mirror_switch = ctk.CTkSwitch(
    app,
    text="Lật ảnh",
    variable=mirror_var,
    onvalue=True,
    offvalue=False
)
mirror_switch.pack(pady=2)

bw_switch = ctk.CTkSwitch(
    app,
    text="Ảnh trắng đen",
    variable=bw_var,
    onvalue=True,
    offvalue=False
)
bw_switch.pack(pady=2)

ctk.CTkButton(app, text="Chạy", command=process_videos_in_threads).pack(pady=20)
app.mainloop()
